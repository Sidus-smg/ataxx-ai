{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbaseconda89d49493410846908a83cfe4240bdc92",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import random\n",
    "class GameDataset(Dataset):\n",
    "    def __init__(self, record, filepath='/home/smg/game_record.pkl'):\n",
    "        self.record = record\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                record_from_file = pickle.load(f)\n",
    "                file_length = len(record_from_file['input'])\n",
    "                use_num = min(file_length, 100000)\n",
    "                sample_key = random.sample(range(file_length), use_num)\n",
    "                record_cut = {'input': [], 'value': [], 'policy': []}\n",
    "                for key in sample_key:\n",
    "                    record_cut['input'].append(record_from_file['input'][key])\n",
    "                    record_cut['policy'].append(record_from_file['policy'][key])\n",
    "                    record_cut['value'].append(record_from_file['value'][key])\n",
    "                record_from_file = record_cut\n",
    "                self.record['input'] += record_from_file['input']\n",
    "                self.record['policy'] += record_from_file['policy']\n",
    "                self.record['value'] += record_from_file['value']\n",
    "                with open('/home/smg/game_record.pkl', 'wb') as f2:\n",
    "                    pickle.dump(self.record, f2)\n",
    "        except:\n",
    "            with open('/home/smg/game_record.pkl', 'wb') as f2:\n",
    "                pickle.dump(self.record, f2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.record['input'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.item()\n",
    "\n",
    "        return {'input': self.record['input'][idx],\n",
    "                'value': self.record['value'][idx],\n",
    "                'policy': self.record['policy'][idx]}\n",
    "\n",
    "initial_state = [[1,0,0,0,0,0,2],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[2,0,0,0,0,0,1]]\n",
    "def self_play(match_num=100):\n",
    "    game_record = {'input': [],\n",
    "                'policy': [],\n",
    "                'value': []}\n",
    "    print('Matching', end=' ')\n",
    "    for i in range(match_num):\n",
    "        AI1 = SidusPlayer(1, use_gpu=True)\n",
    "        AI2 = SidusPlayer(2, use_gpu=True)\n",
    "        board = initial_state\n",
    "        turn = 0\n",
    "        max_turn = 100\n",
    "        while turn < max_turn:\n",
    "            move_1 = AI1.move(board, max_visit=20, is_train=True)\n",
    "            if move_1 != tuple():\n",
    "                policy = get_move_key(move_1[0][0], move_1[0][1], move_1[1][0], move_1[1][1])\n",
    "            else:\n",
    "                policy = 24\n",
    "            tensor_input_1 = list_to_tensor_input(board, 1)\n",
    "            game_record['input'].append(tensor_input_1)\n",
    "            game_record['policy'].append(torch.tensor(policy, dtype=torch.long))\n",
    "            board = update_board(board, move_1)\n",
    "            if is_end(board) or turn >= max_turn:\n",
    "                if get_winner(board, 1, 2) == 1:\n",
    "                    value_1st = 1\n",
    "                else:\n",
    "                    value_1st = -1\n",
    "                v = value_1st\n",
    "                while len(game_record['value']) < len(game_record['input']):\n",
    "                    game_record['value'].append(torch.tensor(v, dtype=torch.float))\n",
    "                    v = -v\n",
    "                break\n",
    "            turn += 1\n",
    "            move_2 = AI2.move(board, max_visit=20, is_train=True)\n",
    "            if move_2 != tuple():\n",
    "                policy = get_move_key(move_2[0][0], move_2[0][1], move_2[1][0], move_2[1][1])\n",
    "            else:\n",
    "                policy = 24\n",
    "            tensor_input_2 = list_to_tensor_input(board, 2)\n",
    "            game_record['input'].append(tensor_input_2)\n",
    "            game_record['policy'].append(torch.tensor(policy, dtype=torch.long))\n",
    "            board = update_board(board, move_2)\n",
    "            if is_end(board) or turn >= max_turn:\n",
    "                if get_winner(board, 1, 2) == 1:\n",
    "                    value_1st = 1\n",
    "                else:\n",
    "                    value_1st = -1\n",
    "                v = value_1st\n",
    "                while len(game_record['value']) < len(game_record['input']):\n",
    "                    game_record['value'].append(torch.tensor(v, dtype=torch.float))\n",
    "                    v = -v\n",
    "                break\n",
    "            turn += 1\n",
    "        print(i, end=' ')\n",
    "    print()\n",
    "    # End of for\n",
    "    return game_record\n",
    "\n",
    "def train(record, epoch_num=10):\n",
    "    print('Training')\n",
    "    datafeeder = GameDataset(record)\n",
    "    randomsampler = torch.utils.data.RandomSampler(datafeeder, replacement=True, num_samples=10000)\n",
    "\n",
    "    net = SidusAtaxxNet()\n",
    "    net.load_state_dict(torch.load('model.pt'))\n",
    "    net.train()\n",
    "    net.cuda()\n",
    "\n",
    "    criterion_pol = nn.NLLLoss()\n",
    "    criterion_val = nn.MSELoss()\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        dataloader = DataLoader(datafeeder, batch_size=32, sampler=randomsampler)\n",
    "        total_loss = 0\n",
    "        loss_pol_sum = 0\n",
    "        loss_val_sum = 0\n",
    "        loss_val_max = -1\n",
    "        loss_val_min = 1\n",
    "        for i, data in enumerate(dataloader):\n",
    "            #print(torch.sum(data['input'][0][0]))\n",
    "            output = net(data['input'].to('cuda'))\n",
    "            policy, value = output\n",
    "            #print(value[0].detach().cpu().item(), data['value'][0])\n",
    "            loss_pol = criterion_pol(policy, data['policy'].to('cuda'))\n",
    "            loss_val = criterion_val(value, data['value'].to('cuda'))\n",
    "            alpha = 1e0\n",
    "            loss = 2 * (loss_pol + alpha * loss_val) / (1 + alpha)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            loss_pol_sum += loss_pol.detach().cpu().item()\n",
    "            loss_val_sum += loss_val.detach().cpu().item()\n",
    "            total_loss += loss.detach().cpu().item()\n",
    "            loss_val_float = loss_val.detach().cpu().item()\n",
    "            if loss_val_float > loss_val_max:\n",
    "                loss_val_max = loss_val_float\n",
    "            if loss_val_float < loss_val_min:\n",
    "                loss_val_min = loss_val_float\n",
    "            print_interval = 100\n",
    "            if i % print_interval == print_interval - 1:\n",
    "                print('[%d, %5d] loss: %.8f\\tpol: %.8f\\tval: %.8f %.5f %.5f' %\n",
    "                    (epoch + 1, i + 1, total_loss/print_interval, loss_pol_sum/print_interval, loss_val_sum/print_interval, loss_val_max, loss_val_min))\n",
    "                total_loss = 0\n",
    "                loss_pol_sum = 0\n",
    "                loss_val_sum = 0\n",
    "                loss_val_max = -1\n",
    "                loss_val_min = 1\n",
    "                torch.save({'epoch': epoch,\n",
    "                            'step': i,\n",
    "                            'model_state_dict': net.state_dict(),\n",
    "                            'optimizer_state_dict': optim.state_dict(),\n",
    "                            'loss': loss}, 'checkpoint_aginst.tar')\n",
    "        torch.save(net.state_dict(), 'model.pt')\n",
    "\n",
    "def compete(match_num, target_num):\n",
    "    print('Competing')\n",
    "    AI_champ = SidusPlayer(1, filepath='model_top.pt', use_gpu=True)\n",
    "    AI_chall = SidusPlayer(2, filepath='model.pt', use_gpu=True)\n",
    "    win_count = 0\n",
    "    for i in range(match_num):\n",
    "        turn = 0\n",
    "        max_turn = 100\n",
    "        board = initial_state\n",
    "        while turn < max_turn:\n",
    "            move_1 = AI_champ.move(board, max_visit=50)\n",
    "            board = update_board(board, move_1)\n",
    "            if is_end(board) or turn >= max_turn:\n",
    "                if get_winner(board, 1, 2) == 2:\n",
    "                    win_count += 1\n",
    "                    print('W', end='')\n",
    "                else:\n",
    "                    print('_', end='')\n",
    "                break\n",
    "            turn += 1\n",
    "            move_2 = AI_chall.move(board, max_visit=50)\n",
    "            board = update_board(board, move_2)\n",
    "            if is_end(board) or turn >= max_turn:\n",
    "                if get_winner(board, 1, 2) == 2:\n",
    "                    win_count += 1\n",
    "                    print('W', end='')\n",
    "                else:\n",
    "                    print('_', end='')\n",
    "                break\n",
    "            turn += 1\n",
    "        if match_num - (i+1) + win_count < target_num:\n",
    "            break\n",
    "    print()\n",
    "    if win_count >= target_num:\n",
    "        torch.save(AI_chall.net.state_dict(), 'model_top.pt')\n",
    "        return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Matching01234"
    }
   ],
   "source": [
    "count = 0\n",
    "while True:\n",
    "    count += 1\n",
    "    for i in range(1):\n",
    "        game_record = self_play(10)\n",
    "        # Train\n",
    "        train(game_record, 10)\n",
    "    new_champ = compete(7, 5)\n",
    "    if new_champ:\n",
    "        print('selfplay {}: New champ'.format(count))\n",
    "    else:\n",
    "        print('selfplay {}: End'.format(count))"
   ]
  },
  {
   "source": [
    "def print_dataset(record, idx):\n",
    "    print('idx', idx)\n",
    "    print(torch.sum(record['input'][idx][0] - record['input'][idx][1]))\n",
    "    print(record['input'][idx][0] - record['input'][idx][1])\n",
    "    pol = record['policy'][idx].item()\n",
    "    print(pol // 7 // 7, (pol // 7) % 7, pol % 7)\n",
    "    print(record['value'][idx])"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training\n"
    }
   ],
   "source": [
    "empty_record = {'input': [],\n",
    "                'policy': [],\n",
    "                'value': []}\n",
    "train(empty_record)"
   ]
  }
 ]
}